data_2016 <- func.df.ToInt(data_2016,columns_To_Int)
data_2016 <- func.df.ToNum(data_2016,columns_To_Num)
data_2016 <- func.df.ToDate(data_2016,list('date'),format="%m/%d/%Y")
data_2016 <- data_2016 %>% filter(!is.na(price))
data_2017 <- func.df.ToInt(data_2017,columns_To_Int)
data_2017 <- func.df.ToNum(data_2017,columns_To_Num)
data_2017 <- func.df.ToDate(data_2017,list('date'),format="%m/%d/%y")
data_2017 <- data_2017 %>% filter(!is.na(price))
data_2018 <- func.df.ToInt(data_2018,columns_To_Int)
data_2018 <- func.df.ToNum(data_2018,columns_To_Num)
data_2018 <- func.df.ToDate(data_2018,list('date'),format="%m/%d/%y")
data_2018 <- data_2018 %>% filter(!is.na(price))
data_2019 <- func.df.ToInt(data_2019,columns_To_Int)
data_2019 <- func.df.ToNum(data_2019,columns_To_Num)
data_2019 <- func.df.ToDate(data_2019,list('date'),format="%m/%d/%y")
data_2019 <- data_2019 %>% filter(!is.na(price))
data_2020 <- func.df.ToInt(data_2020,columns_To_Int)
data_2020 <- func.df.ToNum(data_2020,columns_To_Num)
data_2020 <- func.df.ToDate(data_2020,list('date'),format="%m/%d/%y")
data_2020 <- data_2020 %>% filter(!is.na(price))
# to get the total observation number of rows.
count_observation_after_processing <- nrow(data_2016) +
nrow(data_2017) +
nrow(data_2018) +
nrow(data_2019) +
nrow(data_2020)
#merge the data frames
data_2016_2020_list <- list(
data_2016,
data_2017,
data_2018,
data_2019,
data_2020
)
data_2016_2020 <- data_2016_2020_list %>% reduce(full_join)
remove(data_2016_2020_list)
#1.3 Filter the data and make transformations specific to this analysis
data_2016_2020_clean <- data_2016_2020 %>%
filter(str_detect(bldclasssale, "^A")
| str_detect(bldclasssale, "^R"))
#the number of total units and the number of residential units are both 1
data_2016_2020_clean <- data_2016_2020_clean %>%
filter(resunits == 1 & totunits == 1)
#additionally restrict the data to observation where gross square
# footage is more than 0
data_2016_2020_clean <- data_2016_2020_clean %>%
filter(grosssqft > 0 & !is.na(grosssqft))
#additionally restrict the data to observation where sale price is
#non-missing
data_2016_2020_clean <- data_2016_2020_clean %>%
filter(!is.na(price))
#additionally restrict the data to observation where Year Built is
#more than 0
data_2016_2020_clean <- data_2016_2020_clean %>%
filter(yrbuilt > 0)
#additionally restrict the data to observation where price is
#less than 100 million. Anything outside of that, I would consider
#those as outliers.
outlier_threhold=10000000
data_2016_2020_clean <- data_2016_2020_clean %>%
filter(price <= outlier_threhold)
#additionally restrict the data to observation where gross sqft is
#less than 20k. Anything outside of that, I would consider those as outliers
grosssqft_threhold=20000
data_2016_2020_clean <- data_2016_2020_clean %>%
filter(grosssqft < grosssqft_threhold)
#2.1.1.1 - Statistics summary
dim(data_2016_2020_clean)
summary(data_2016_2020_clean)
#2.1.1.2 - Check for any NA’s in the dataframe
missmap(
data_2016_2020_clean,
col=c('yellow','black'),
y.at=1,
y.labels='',legend=TRUE
)
colSums(is.na(data_2016_2020_clean))
#2.1.1.3 - Data Cleansing — Handle missing data
data_2016_2020_clean[["taxclasscurr"]][
str_detect(data_2016_2020_clean[["bldclasssale"]], "^A")
& is.na(data_2016_2020_clean[["taxclasscurr"]])] <- 1
data_2016_2020_clean[["taxclasscurr"]][
str_detect(data_2016_2020_clean[["bldclasssale"]], "^R")
& is.na(data_2016_2020_clean[["taxclasscurr"]])] <- 2
data_2016_2020_clean[["comunits"]][
is.na(data_2016_2020_clean[["comunits"]])] <- 0
# make sure no columns has NA any more.
colSums(is.na(data_2016_2020_clean))
#By looking at the correlation coefficient of the independent
#variables 'taxclasscurr', 'taxclasssale', 'landsqft', 'lot'
#with the target variable 'price' are weak correlations,
#(0.1, 0.1, 0.1, 0.1 respectively)
#'therefore we can exclude these four independent variable from our model.
ggcorr(
data_2016_2020_clean,
label = T,
hjust = 1,
legend.position="top",
layout.exp = 2
)
#2.1.1.5 - visualizing the distribution of the target variable 'price'
# and draw kernel density estimate.
data_2016_2020_clean %>%
ggplot(aes(price)) +
geom_density() +
theme_bw()
#2.1.3.1 - Additionally restrict the data to observation where
#price is greater than 0
data_2016_2020_clean <-
data_2016_2020_clean %>% filter(price > 0 & !is.na(price))
#2.1.3.2 - Additionally restrict the data to observation where
#zip is greater than 0
data_2016_2020_clean <-
data_2016_2020_clean %>% filter(zip > 0)
#2.1.3.3 - visualizing the distribution of the target variable 'price'
data_2016_2020_clean %>%
ggplot(aes(price)) +
geom_density() +
theme_bw()
#2.1.3.4 - Create a histogram of housing prices
ggplot(data=data_2016_2020_clean) +
geom_histogram(mapping = aes(price))
ggplot(data=data_2016_2020_clean) +
geom_histogram(mapping = aes(price/100000),
breaks=seq(0, 7, by = 1), col="red", fill="lightblue") +
geom_density(mapping = aes(x=price/100000, y = (..count..)))  +
labs(title="Housing Prices in $100,000",
x="Sale Price of Individual Homes/Condos")
ggplot(data=data_2016_2020_clean) +
geom_point(mapping= aes(x=grosssqft, y=price))
ggplot(data=data_2016_2020_clean) +
geom_point(mapping= aes(x=log(grosssqft), y=price))
ggplot(data=data_2016_2020_clean) +
geom_point(mapping= aes(x=yrbuilt, y=price))
ggplot(data=data_2016_2020_clean) +
geom_point(mapping= aes(x=price, y=bldclasssale))
ggplot(data=data_2016_2020_clean) +
geom_point(mapping= aes(x=price, y=zip))
ggplot(data=data_2016_2020_clean) +
geom_point(mapping= aes(x=price, y=block))
ggplot(data=data_2016_2020_clean) +
geom_point(mapping= aes(x=price, y=neighborhood))
#2.1.3.5 - effect of the predictor variables on target variable 'price'
data_2016_2020_clean %>%
dplyr::select(c(
price,
zip,
# neighborhood,
# block,
grosssqft,
# landsqft,
yrbuilt,
bldclasssale,
# taxclasssale
)) %>%
melt(id.vars = "price") %>%
ggplot(aes(x = value, y = price, colour = variable)) +
geom_point(alpha = 0.7) +
stat_smooth(aes(colour = "black")) +
facet_wrap(~variable, scales = "free", ncol = 2) +
labs(x = "Variable Value", y = "Price ($1000s)") +
theme_gray()
#2.2.1.1 - find the average price of each neighborhood and assign that
# price to price having 0 for those matching neighborhood. We first
# need to know what are the unique_neighborhoods and unique_neighborhoods.
unique_neighborhoods <- as.list(unique(data_2016_2020_clean$neighborhood))
unique_zips <- as.list(unique(data_2016_2020_clean$zip))
columns_with_duplicates <- c('neighborhood',
'bldclasscat',
'block',
'zip',
'resunits',
'totunits',
'landsqft',
'grosssqft',
'yrbuilt',
'bldclasssale',
'price'
)
data_2016_2020_clean <- data_2016_2020_clean[
!duplicated(
data_2016_2020_clean, by=columns_with_duplicates), ]
#2.2.1.3 - find duplicate rows with same values for column
#(neighborhood,bldclasscat,block,zip,resunits,totunits,landsqft,
#grosssqft,yrbuilt,bldclasssale)
data_2016_2020_clean <- data_2016_2020_clean %>%
group_by(
neighborhood,
address,
bldclasscat,
block,
zip,
resunits,
totunits,
landsqft,
grosssqft,
yrbuilt,
bldclasssale
) %>%
mutate(duplicate_row = case_when(
n()>1  ~ 1,
TRUE  ~ 0
))
data_2016_2020_clean <- func.df.ToInt(
data_2016_2020_clean,list('duplicate_row')
)
#2.2.1.4 - find the average price of each neighborhood and
#corresponding zip. Some houses are sold with less than 3000 USD,
# we assign the average price from their neighborhood and zip to
# those price-unreasonable houses with those matching neighborhood and zip.
# We create a function to do this.
func.df.adjPrice <- function(df, neighborhoods, zips) {
df$adjprice = df$price
colname_price = 'adjprice'
colname_neighborhood = 'neighborhood'
colname_zip = 'zip'
threshold_price=3000
group_by_neighbour_zip <- df %>%
filter(is.element(
neighborhood,
unique_neighborhoods) &
price > threshold_price) %>%
group_by(neighborhood, zip) %>%
summarise(mean_price=floor(mean(price)), .groups = 'drop') %>%
as.data.frame()
for(i in 1:nrow(group_by_neighbour_zip)) {
row <- group_by_neighbour_zip[i,]
col_neighborhood_val <- row[,1]
col_zip_val <- row[,2]
col_mean_price_val <- row[,3]
df[[colname_price]][df[[colname_price]] > 0 &
df[[colname_price]] <= threshold_price &
df[[colname_neighborhood]] == col_neighborhood_val &
df[[colname_zip]] == col_zip_val] <- col_mean_price_val
}
return(df)
}
# run the function to fill the adjusted prices to all rows.
data_2016_2020_clean <- func.df.adjPrice(
data_2016_2020_clean,
unique_neighborhoods,
unique_zips
)
#2.2.1.5 - Set landsqft equals grosssqft if landsqft less than 0
data_2016_2020_clean <- data_2016_2020_clean %>%
mutate(adjlandsqft = case_when(
landsqft <= 0  ~ grosssqft,
TRUE  ~ landsqft
))
data_2016_2020_clean <-
func.df.ToNum(data_2016_2020_clean,list('adjlandsqft'))
#2.2.2.1 - extract year from sale date
data_2016_2020_clean$yrsold <-
format(data_2016_2020_clean$date,"%Y")
#2.2.3.2 - convert the column to integer type.
data_2016_2020_clean <-
func.df.ToInt(data_2016_2020_clean,list('yrsold'))
#2.2.3.3 - adding quarter by extracting month from date
data_2016_2020_clean <- data_2016_2020_clean %>%
mutate(quarter = case_when(
is.element(format(date,"%m"), c("01", "02", "03"))  ~ 1,
is.element(format(date,"%m"), c("04", "05", "06"))  ~ 2,
is.element(format(date,"%m"), c("07", "08", "09"))  ~ 3,
is.element(format(date,"%m"), c("10", "11", "12"))  ~ 4
))
#2.2.3.4 - convert the column to integer type.
data_2016_2020_clean <-
func.df.ToInt(data_2016_2020_clean,list('quarter'))
#2.2.4.1 - group all "A5" "A1" "A9" "A4" "A3" "A2" "A0" "A7" "A6" to "A"
#2.2.4.2 - group all "R3" "R2" "R4" "R1" "R6" "RR" to "R"
data_2016_2020_clean <- data_2016_2020_clean %>%
mutate(bldclasssalecategory = case_when(
str_detect(bldclasssale, "^A")  ~ "0",
str_detect(bldclasssale, "^R")  ~ "1"
))
# convert the column to int.
data_2016_2020_clean <- func.df.ToInt(
data_2016_2020_clean,list('bldclasssalecategory')
)
#2.2.5.1 - log transformations of predictors
data_2016_2020_clean$log_house_age <-
log(data_2016_2020_clean$yrsold -
data_2016_2020_clean$yrbuilt +
0.1
)
#2.2.6.1 - Let's identify significance level from interaction between variables
summary(lm(formula = adjprice~
(factor(bldclasssalecategory)+
factor(zip)+
grosssqft+
adjlandsqft+
block+
lot+
log_house_age+
yrbuilt+
borough+
factor(bldclasscat)+
factor(taxclasssale))^2,
data_2016_2020_clean))
#2.3 - Reach a stopping point
#New version of model by adding interaction terms
transform.lm <- lm(formula = adjprice~factor(bldclasssalecategory)*
grosssqft+
factor(zip)+
log_house_age,
data_2016_2020_clean
)
transform.lm.summary <-
summary(transform.lm)
transform.lm.summary
RMSE_transform_v2_model <- sqrt(
mean(transform.lm.summary$residuals^2)
)
sprintf("Root Mean Square Error(RMSE) for Transformed V2 Model : %s",
round(RMSE_transform_v2_model, digits = 4))
transform.lm.summary <-
summary(transform.lm)
transform.lm.summary
RMSE_model <- sqrt(
mean(transform.lm.summary$residuals^2)
)
sprintf("Root Mean Square Error(RMSE) for Transformed V2 Model : %s",
round(RMSE_model, digits = 4))
#2.3.0.1 - Test IID assumptions
#Kolmogorov-Smirnov test for normality
hist(transform.lm$residuals)
ks.test(transform.lm$residuals/summary(transform.lm)$sigma, pnorm)
#Breusch-Pagan test for normality heteroscedasticity
bptest(transform.lm)
#If the residuals become more spread out at higher values in the plot,
#this is a tell-tale sign that heteroscedasticity is present.
plot(fitted(transform.lm),
resid(transform.lm),
col = "dodgerblue",
pch = 20, cex = 1.5,
xlab = "Fitted",
ylab = "Residuals")
abline(h = 0, lty = 2, col = "darkorange", lwd = 2)
#2.2.5.5 - a scale-location plot
ggplot(transform.lm,
aes(x=.fitted, y=sqrt(abs(.stdresid)))) +
geom_point() +
geom_hline(yintercept = 0) +
geom_smooth() +
ggtitle("Scale-Location plot : Standardized Residual vs Fitted values")
#2.2.5.6 - normal QQ plot
ggplot(data_2016_2020_clean, aes(sample=transform.lm$residuals)) +
stat_qq() +
stat_qq_line() +
labs(title = "QQ Plot of BC Model")
# 2.3, to get property sold in Q3 and Q4 2020.
q3_2020_sold <- filter(data_2016_2020_clean,
yrsold == "2020", quarter =="3" )
q4_2020_sold <- filter(data_2016_2020_clean,
yrsold == "2020", quarter =="4" )
# average sold price at Q4, USD 1070895.
average_sold_price_q4 <- mean(q4_2020_sold$adjprice)
#  average sold price at Q3, USD 957949.9
average_sold_price_q3 <- mean(q3_2020_sold$adjprice)
# average sold price all property types, quarter 4 over quarter 3.
average_sold_price_change <- (
average_sold_price_q4 - average_sold_price_q3)/average_sold_price_q3
# 0.1179029
average_sold_price_change
# number of sold properties
# 339 and 573
q3_count <- nrow(q3_2020_sold)
q4_count <- nrow(q4_2020_sold)
# number of sold properties increase rate
properties_sold_increase_rate <- (q4_count - q3_count)/q3_count
# 0.6902655
properties_sold_increase_rate
# get all types of residential class
residential_class_price_q3 <- filter(q3_2020_sold, str_detect(bldclasssale, "^A"))
residential_class__price_q4 <- filter(q4_2020_sold, str_detect(bldclasssale, "^A"))
q3_mean <- mean(residential_class_price_q3$adjprice)
q4_mean <- mean(residential_class__price_q4$adjprice)
increase_rate <- (q4_mean - q3_mean)/q4_mean
# get all types of condo class
condo_class_q3 <- filter(q3_2020_sold, str_detect(bldclasssale, "^R"))
condo_class_q4 <- filter(q4_2020_sold, str_detect(bldclasssale, "^R"))
q3_mean <- mean(condo_class_q3$adjprice)
q4_mean <- mean(condo_class_q4$adjprice)
increase_rate <- (q4_mean - q3_mean)/q3_mean
# Step 3: Submit model and work.
saveRDS(list(model=transform.lm,
data=data_2016_2020_clean),
file="qingwei_zhang.RDS"
)
# 2.3, to get property sold in Q3 and Q4 2020.
q3_2020_sold <- filter(data_2016_2020_clean,
yrsold == "2020", quarter =="3" )
q4_2020_sold <- filter(data_2016_2020_clean,
yrsold == "2020", quarter =="4" )
# average sold price at Q4, USD 1070895.
average_sold_price_q4 <- mean(q4_2020_sold$adjprice)
#  average sold price at Q3, USD 957949.9
average_sold_price_q3 <- mean(q3_2020_sold$adjprice)
average_sold_price_q4
average_sold_price_q3
# average sold price all property types, quarter 4 over quarter 3.
average_sold_price_change <- (
average_sold_price_q4 - average_sold_price_q3)/average_sold_price_q3
# average sold price all property types, quarter 4 over quarter 3.
average_sold_price_change <- (
average_sold_price_q4 - average_sold_price_q3)/average_sold_price_q3
# average sold price all property types, quarter 4 over quarter 3.
average_sold_price_change <- (
average_sold_price_q4 - average_sold_price_q3)/average_sold_price_q3
# 0.1179029
average_sold_price_change
# get all types of residential class
residential_class_price_q3 <- filter(q3_2020_sold, str_detect(bldclasssale, "^A"))
residential_class__price_q4 <- filter(q4_2020_sold, str_detect(bldclasssale, "^A"))
q3_mean <- mean(residential_class_price_q3$adjprice)
q4_mean <- mean(residential_class__price_q4$adjprice)
increase_rate <- (q4_mean - q3_mean)/q4_mean
q3_mean
q4_mean
increase_rate
# get all types of condo class
condo_class_q3 <- filter(q3_2020_sold, str_detect(bldclasssale, "^R"))
condo_class_q4 <- filter(q4_2020_sold, str_detect(bldclasssale, "^R"))
q3_mean <- mean(condo_class_q3$adjprice)
q4_mean <- mean(condo_class_q4$adjprice)
increase_rate <- (q4_mean - q3_mean)/q3_mean
q3_mean
q4_mean
q4_mean <- mean(condo_class_q4$adjprice)
increase_rate
# 2.3, to get property sold in Q3 and Q4 2020.
q3_2020_sold <- filter(data_2016_2020_clean,
yrsold == "2020", quarter =="3" )
q4_2020_sold <- filter(data_2016_2020_clean,
yrsold == "2020", quarter =="4" )
# average sold price at Q4, USD 1070895.
average_sold_price_q4 <- mean(q4_2020_sold$adjprice)
average_sold_price_q4
#  average sold price at Q3, USD 957949.9
average_sold_price_q3 <- mean(q3_2020_sold$adjprice)
average_sold_price_q3
# average sold price all property types, quarter 4 over quarter 3.
average_sold_price_change <- (
average_sold_price_q4 - average_sold_price_q3)/average_sold_price_q3
average_sold_price_change
# number of sold properties
# 339 and 573
q3_count <- nrow(q3_2020_sold)
q4_count <- nrow(q4_2020_sold)
# number of sold properties increase rate
properties_sold_increase_rate <- (q4_count - q3_count)/q3_count
# 0.6902655
properties_sold_increase_rate
# get all types of residential class
residential_class_price_q3 <- filter(q3_2020_sold, str_detect(bldclasssale, "^A"))
residential_class__price_q4 <- filter(q4_2020_sold, str_detect(bldclasssale, "^A"))
q3_mean <- mean(residential_class_price_q3$adjprice)
q4_mean <- mean(residential_class__price_q4$adjprice)
increase_rate <- (q4_mean - q3_mean)/q4_mean
q3_mean
q4_mean
increase_rate
# get all types of condo class
condo_class_q3 <- filter(q3_2020_sold, str_detect(bldclasssale, "^R"))
condo_class_q4 <- filter(q4_2020_sold, str_detect(bldclasssale, "^R"))
q3_mean <- mean(condo_class_q3$adjprice)
q4_mean <- mean(condo_class_q4$adjprice)
increase_rate <- (q4_mean - q3_mean)/q3_mean
increase_rate
of residential class
# get all types of residential class
residential_class_price_q3 <- filter(q3_2020_sold, str_detect(bldclasssale, "^A"))
residential_class__price_q4 <- filter(q4_2020_sold, str_detect(bldclasssale, "^A"))
q3_mean <- mean(residential_class_price_q3$adjprice)
q3_mean
q4_mean <- mean(residential_class__price_q4$adjprice)
q4_mean
increase_rate <- (q4_mean - q3_mean)/q3_mean
increase_rate
# get all types of condo class
condo_class_q3 <- filter(q3_2020_sold, str_detect(bldclasssale, "^R"))
condo_class_q4 <- filter(q4_2020_sold, str_detect(bldclasssale, "^R"))
q3_mean <- mean(condo_class_q3$adjprice)
q4_mean <- mean(condo_class_q4$adjprice)
increase_rate <- (q4_mean - q3_mean)/q3_mean
q3_mean
q4_mean
nrow(residential_class_price_q3)
nrow(residential_class_price_q4)
residential_class_price_q4 <- filter(q4_2020_sold, str_detect(bldclasssale, "^A"))
nrow(residential_class_price_q3)
residential_class_price_q4 <- filter(q4_2020_sold, str_detect(bldclasssale, "^A"))
nrow(residential_class_price_q3)
nrow(residential_class_price_q4)
rate<-(count_res_q4-count_res_q3)/count_res_q3
count_res_q3 <- nrow(residential_class_price_q3)
count_res_q4 <- nrow(residential_class_price_q4)
rate<-(count_res_q4-count_res_q3)/count_res_q3
rate
# Number of sold residential properties
count_res_q3 <- nrow(condo_class_q3)
count_res_q4 <- nrow(condo_class_q4)
rate<-(count_res_q4-count_res_q3)/count_res_q3
# Number of sold residential properties
count_condo_q3 <- nrow(condo_class_q3)
count_condo_q4 <- nrow(condo_class_q4)
rate<-(count_condo_q4-count_condo_q3)/count_condo_q3
count_condo_q3
count_condo_q4
rate
rate <- (count_condo_q4-count_condo_q3)/count_condo_q3
rate
